{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import transformers\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import wandb\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "\n",
    "from utils import normalize_sitk_image, MRI_Dataset_within_ROI, MRI_Dataset_within_ROI_both_prepost\n",
    "\n",
    "from torchvision.transforms import v2\n",
    "import torchio as tio\n",
    "\n",
    "from torchmetrics import Accuracy, Recall, Precision, F1Score\n",
    "\n",
    "\n",
    "torch.set_num_threads(12)\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "SIZE = (100,100,100)\n",
    "TRAIN_SPLIT = 0.75\n",
    "SPLIT_SEED = 123456789\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "DATA_PATH = '../../../Processed NIFTI Dataset/'\n",
    "CLASSIFICATION = 'ER'\n",
    "dataset_path = f'../../Train Test Splits/{CLASSIFICATION}/'\n",
    "\n",
    "MODEL_SAVE_PATH = f'basic_model_{CLASSIFICATION}.pth'\n",
    "PROJECT_NAME = 'Breast Cancer Subtype Prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset loading\n",
    "\n",
    "train_set = pd.read_csv(dataset_path + 'train.csv')\n",
    "test_set  = pd.read_csv(dataset_path + 'test.csv')\n",
    "\n",
    "bounding_boxes = pd.read_csv('../../Data/segmentation_annotations_NIFTI.csv').set_index('Patient_ID')\n",
    "\n",
    "NUM_CLASSES = len(train_set['label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation set split\n",
    "\n",
    "train_set, val_set = train_test_split(train_set, train_size = TRAIN_SPLIT, stratify = train_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "\n",
    "transform = v2.Compose([\n",
    "    tio.ZNormalization()\n",
    "    # v2.Normalize(mean = [0.5], std = [0.225])\n",
    "])\n",
    "\n",
    "upscaler = tio.Resize(SIZE, 'bspline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_args = {\n",
    "        'scales' : [0.8, 1, 0.8, 1, 0.8, 1],\n",
    "        'degrees' : 15,\n",
    "        'translation' : [0.05, 0.05, 0.05],\n",
    "        'center' : 'image'\n",
    "}\n",
    "\n",
    "augment = tio.Compose([\n",
    "    tio.transforms.RandomFlip(axes = (0, 1, 2)),\n",
    "    tio.transforms.RandomAffine(\n",
    "        **affine_args\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Datasets\n",
    "\n",
    "# train_dataset = MRI_Dataset_within_ROI(DATA_PATH,\n",
    "#                                        train_set,\n",
    "#                                        bounding_boxes, \n",
    "#                                        transform,\n",
    "#                                        upscaler,\n",
    "#                                     #    augment = augment\n",
    "#                                        )\n",
    "\n",
    "# val_dataset = MRI_Dataset_within_ROI(DATA_PATH,\n",
    "#                                        val_set,\n",
    "#                                        bounding_boxes, \n",
    "#                                        transform,\n",
    "#                                        upscaler)\n",
    "\n",
    "# test_dataset = MRI_Dataset_within_ROI(DATA_PATH,\n",
    "#                                        test_set,\n",
    "#                                        bounding_boxes, \n",
    "#                                        transform,\n",
    "#                                        upscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "\n",
    "train_dataset = MRI_Dataset_within_ROI_both_prepost(DATA_PATH,\n",
    "                                       train_set,\n",
    "                                       bounding_boxes, \n",
    "                                       transform,\n",
    "                                       upscaler,\n",
    "                                    #    augment = augment\n",
    "                                       )\n",
    "\n",
    "val_dataset = MRI_Dataset_within_ROI_both_prepost(DATA_PATH,\n",
    "                                       val_set,\n",
    "                                       bounding_boxes, \n",
    "                                       transform,\n",
    "                                       upscaler)\n",
    "\n",
    "test_dataset = MRI_Dataset_within_ROI_both_prepost(DATA_PATH,\n",
    "                                       test_set,\n",
    "                                       bounding_boxes, \n",
    "                                       transform,\n",
    "                                       upscaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataloaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           shuffle = True,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           pin_memory = True,\n",
    "                                           num_workers = 2\n",
    "                                           )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           pin_memory = True,\n",
    "                                           num_workers = 2\n",
    "                                           )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           pin_memory = True,\n",
    "                                           num_workers = 2\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet_MRI3D(torch.nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(ConvNet_MRI3D, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv3d(in_channels, 16, kernel_size = (3,3,3), stride = (1,1,1), padding = 1)\n",
    "        self.conv2 = torch.nn.Conv3d(16, 16, kernel_size = (3,3,3), stride = (1,1,1), padding = 1)\n",
    "        self.conv3 = torch.nn.Conv3d(16, 16, kernel_size = (3,3,3), stride = (1,1,1), padding = 1)\n",
    "        self.conv4 = torch.nn.Conv3d(16, 16, kernel_size = (3,3,3), stride = (1,1,1), padding = 1)\n",
    "        \n",
    "        self.conv1x1_1 = torch.nn.Conv3d(16, 16, kernel_size=1, stride=1)\n",
    "        self.conv1x1_2 = torch.nn.Conv3d(16, 16, kernel_size=1, stride=1)\n",
    "        self.maxpool1 = torch.nn.MaxPool3d(2)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(3456, num_classes)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        out = inp\n",
    "        out = F.relu(self.conv1(out))\n",
    "        intermediate = self.maxpool1(out)\n",
    "        \n",
    "        \n",
    "        out = F.relu(self.conv2(intermediate))\n",
    "        out = out + self.conv1x1_1(intermediate)      # residual\n",
    "        intermediate = self.maxpool1(out)\n",
    "        \n",
    "        out = F.relu(self.conv3(intermediate))\n",
    "        out = out + self.conv1x1_2(intermediate)\n",
    "\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.maxpool1(out)\n",
    "        out = self.flatten(out)\n",
    "        \n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(ConvNet_MRI3D(2, 2), input_size=(20,2,100,100,100), col_names = ['input_size', 'output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0001\n",
    "EPOCHS = 10\n",
    "\n",
    "model = ConvNet_MRI3D(2, NUM_CLASSES).to(DEVICE)\n",
    "optim = torch.optim.Adam(model.parameters(), lr = LR)\n",
    "\n",
    "# wandb.login()\n",
    "# wandb.init(\n",
    "#     project = PROJECT_NAME,\n",
    "#     name = CLASSIFICATION,\n",
    "\n",
    "#     config = {\n",
    "#         'learning_rate': LR,\n",
    "#         'architecture': \"3D ConvNet\",\n",
    "#         'epochs' : EPOCHS,\n",
    "#         'batch_size': BATCH_SIZE\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5135, 1.4865], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.tensor((train_set['label'].value_counts()/len(train_set)).to_numpy())\n",
    "weights = 1/weights\n",
    "weights /= weights.min()\n",
    "weights = weights.float().to(DEVICE)\n",
    "weights = weights/weights.mean()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.40904389260101515: 100%|██████████| 97/97 [02:24<00:00,  1.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7370600700378418, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3807996062573439: 100%|██████████| 97/97 [02:05<00:00,  1.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3648752240969281: 100%|██████████| 97/97 [02:05<00:00,  1.30s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3709760159562587: 100%|██████████| 97/97 [02:06<00:00,  1.30s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3717754186433788: 100%|██████████| 97/97 [02:06<00:00,  1.30s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3543183697121484: 100%|██████████| 97/97 [02:05<00:00,  1.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3567116712345346: 100%|██████████| 97/97 [02:05<00:00,  1.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.35058640602274216: 100%|██████████| 97/97 [02:06<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3465940893683621: 100%|██████████| 97/97 [02:04<00:00,  1.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7432712316513062, Validation Accuracy: 0.7469135522842407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.3350946472853607: 100%|██████████| 97/97 [02:04<00:00,  1.29s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.7453415989875793, Validation Accuracy: 0.7469135522842407\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "train_metrics = []\n",
    "\n",
    "scaler = torch.cuda.amp.grad_scaler.GradScaler()\n",
    "CrossEntropyLoss = torch.nn.CrossEntropyLoss(weight = weights).to(DEVICE)\n",
    "\n",
    "acc_train = Accuracy(task = 'multiclass', num_classes = NUM_CLASSES, top_k = 1).to(DEVICE)\n",
    "acc_val = Accuracy(task = 'multiclass', num_classes = NUM_CLASSES, top_k = 1).to(DEVICE)\n",
    "\n",
    "recall_train = Recall(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "recall_val = Recall(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "precision_train = Precision(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "precision_val = Precision(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "f1_train = F1Score(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "f1_val = F1Score(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    epoch_loss = 0\n",
    "    samples = 0\n",
    "    #set model to train\n",
    "    model.train()\n",
    "    for data in (pbar:= tqdm(train_loader)):\n",
    "        #zero optim grad\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        img, labels = data\n",
    "\n",
    "        # append to sampels\n",
    "        n_batch = len(img)\n",
    "        samples+= n_batch\n",
    "\n",
    "        # to device\n",
    "        img = img.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        #forward step\n",
    "        with torch.autocast(device_type = 'cuda', dtype = torch.float16):\n",
    "            outputs = model(img)\n",
    "            loss = CrossEntropyLoss(outputs, labels)\n",
    "        \n",
    "\n",
    "        # backward step\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optim)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss+= (loss.item() * n_batch)\n",
    "        pbar.set_description(f\"CE Loss: {epoch_loss/samples}\")\n",
    "\n",
    "        # accuracy and metrics\n",
    "        acc_train(outputs, labels)\n",
    "        precision_train(outputs, labels)\n",
    "        recall_train(outputs,labels)\n",
    "        f1_train(outputs, labels)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0\n",
    "    val_samples = 0\n",
    "    for data in (val_loader):\n",
    "        val_img, val_labels = data\n",
    "\n",
    "        # append to sampels\n",
    "        n_batch_val = len(img)\n",
    "        val_samples+= n_batch_val\n",
    "\n",
    "        # to device\n",
    "        val_img = val_img.to(DEVICE)\n",
    "        val_labels = val_labels.to(DEVICE)\n",
    "\n",
    "\n",
    "        with torch.no_grad():  \n",
    "            val_outputs = model(val_img)\n",
    "            v_loss = CrossEntropyLoss(val_outputs, val_labels)\n",
    "            val_loss+= (v_loss.item() * n_batch_val)\n",
    "\n",
    "        # metrics\n",
    "        acc_val(val_outputs, val_labels)\n",
    "        precision_val(val_outputs, val_labels)\n",
    "        recall_val(val_outputs, val_labels)\n",
    "        f1_val(val_outputs, val_labels)\n",
    "\n",
    "    logging_dict = {\n",
    "        'epoch': epoch,\n",
    "        'train_loss': epoch_loss/samples,\n",
    "        'val_loss': val_loss/val_samples,\n",
    "        \n",
    "        \n",
    "        'train_acc': acc_train.compute(),\n",
    "        'train_rec': recall_train.compute(),\n",
    "        'train_prec': precision_train.compute(),\n",
    "        'train_f1': f1_train.compute(),\n",
    "        \n",
    "        'val_acc_top1': acc_val.compute(),\n",
    "        'val_rec': recall_val.compute(),\n",
    "        'val_prec': precision_val.compute(),\n",
    "        'val_f1' : f1_val.compute()\n",
    "    }\n",
    "    \n",
    "    print('Training Accuracy: {}, Validation Accuracy: {}'.format(logging_dict['train_acc'].item(), logging_dict['val_acc_top1'].item()))\n",
    "    \n",
    "    train_metrics.append(logging_dict)\n",
    "    \n",
    "    acc_train.reset()\n",
    "    acc_val.reset()\n",
    "    recall_train.reset()\n",
    "    recall_val.reset()\n",
    "    f1_train.reset()\n",
    "    f1_val.reset()\n",
    "    precision_train.reset()\n",
    "    precision_val.reset()\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    # wandb.save(MODEL_SAVE_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"training_logs.pkl\", 'wb') as file:\n",
    "    pkl.dump(train_metrics, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [01:15<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "model.eval()\n",
    "\n",
    "acc_test = Accuracy(task = 'multiclass', num_classes = NUM_CLASSES, top_k = 1).to(DEVICE)\n",
    "recall_test = Recall(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "precision_test = Precision(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "f1_test = F1Score(task = 'multiclass', num_classes = NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "test_loss = 0\n",
    "test_samples = 0\n",
    "for data in (pbar:= tqdm(test_loader)):\n",
    "    test_img, test_labels = data\n",
    "\n",
    "    # append to sampels\n",
    "    n_batch_test = len(img)\n",
    "    test_samples+= n_batch_test\n",
    "\n",
    "    # to device\n",
    "    test_img = test_img.to(DEVICE)\n",
    "    test_labels = test_labels.to(DEVICE)\n",
    "\n",
    "\n",
    "    with torch.no_grad():  \n",
    "        test_outputs = model(test_img)\n",
    "        t_loss = CrossEntropyLoss(test_outputs, test_labels)\n",
    "        test_loss+= (t_loss.item() * n_batch_test)\n",
    "\n",
    "    # metrics\n",
    "    acc_test(test_outputs, test_labels)\n",
    "    precision_test(test_outputs, test_labels)\n",
    "    recall_test(test_outputs, test_labels)\n",
    "    f1_test(test_outputs, test_labels)\n",
    "test_metrics = {\n",
    "    'test_acc': acc_test.compute(),\n",
    "    'test_rec': recall_test.compute(),\n",
    "    'test_prec': precision_test.compute(),\n",
    "    'test_f1': f1_test.compute(),\n",
    "}\n",
    "# wandb.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open(\"testing_logs.pkl\", 'wb') as file:\n",
    "    pkl.dump(test_metrics, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>train_rec</th>\n",
       "      <th>train_prec</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>val_acc_top1</th>\n",
       "      <th>val_rec</th>\n",
       "      <th>val_prec</th>\n",
       "      <th>val_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.409044</td>\n",
       "      <td>0.383698</td>\n",
       "      <td>tensor(0.7371, device='cuda:0')</td>\n",
       "      <td>tensor(0.7371, device='cuda:0')</td>\n",
       "      <td>tensor(0.7371, device='cuda:0')</td>\n",
       "      <td>tensor(0.7371, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.379476</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.364875</td>\n",
       "      <td>0.413584</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.370976</td>\n",
       "      <td>0.406642</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.371775</td>\n",
       "      <td>0.398275</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.354318</td>\n",
       "      <td>0.385302</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.356712</td>\n",
       "      <td>0.380451</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.350586</td>\n",
       "      <td>0.373581</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.346594</td>\n",
       "      <td>0.409120</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7433, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.335095</td>\n",
       "      <td>0.373481</td>\n",
       "      <td>tensor(0.7453, device='cuda:0')</td>\n",
       "      <td>tensor(0.7453, device='cuda:0')</td>\n",
       "      <td>tensor(0.7453, device='cuda:0')</td>\n",
       "      <td>tensor(0.7453, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "      <td>tensor(0.7469, device='cuda:0')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  val_loss                        train_acc  \\\n",
       "0      1    0.409044  0.383698  tensor(0.7371, device='cuda:0')   \n",
       "1      2    0.380800  0.379476  tensor(0.7433, device='cuda:0')   \n",
       "2      3    0.364875  0.413584  tensor(0.7433, device='cuda:0')   \n",
       "3      4    0.370976  0.406642  tensor(0.7433, device='cuda:0')   \n",
       "4      5    0.371775  0.398275  tensor(0.7433, device='cuda:0')   \n",
       "5      6    0.354318  0.385302  tensor(0.7433, device='cuda:0')   \n",
       "6      7    0.356712  0.380451  tensor(0.7433, device='cuda:0')   \n",
       "7      8    0.350586  0.373581  tensor(0.7433, device='cuda:0')   \n",
       "8      9    0.346594  0.409120  tensor(0.7433, device='cuda:0')   \n",
       "9     10    0.335095  0.373481  tensor(0.7453, device='cuda:0')   \n",
       "\n",
       "                         train_rec                       train_prec  \\\n",
       "0  tensor(0.7371, device='cuda:0')  tensor(0.7371, device='cuda:0')   \n",
       "1  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "2  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "3  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "4  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "5  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "6  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "7  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "8  tensor(0.7433, device='cuda:0')  tensor(0.7433, device='cuda:0')   \n",
       "9  tensor(0.7453, device='cuda:0')  tensor(0.7453, device='cuda:0')   \n",
       "\n",
       "                          train_f1                     val_acc_top1  \\\n",
       "0  tensor(0.7371, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "1  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "2  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "3  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "4  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "5  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "6  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "7  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "8  tensor(0.7433, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "9  tensor(0.7453, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "\n",
       "                           val_rec                         val_prec  \\\n",
       "0  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "1  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "2  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "3  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "4  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "5  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "6  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "7  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "8  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "9  tensor(0.7469, device='cuda:0')  tensor(0.7469, device='cuda:0')   \n",
       "\n",
       "                            val_f1  \n",
       "0  tensor(0.7469, device='cuda:0')  \n",
       "1  tensor(0.7469, device='cuda:0')  \n",
       "2  tensor(0.7469, device='cuda:0')  \n",
       "3  tensor(0.7469, device='cuda:0')  \n",
       "4  tensor(0.7469, device='cuda:0')  \n",
       "5  tensor(0.7469, device='cuda:0')  \n",
       "6  tensor(0.7469, device='cuda:0')  \n",
       "7  tensor(0.7469, device='cuda:0')  \n",
       "8  tensor(0.7469, device='cuda:0')  \n",
       "9  tensor(0.7469, device='cuda:0')  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_d = pd.DataFrame.from_dict(train_metrics)\n",
    "train_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_acc': tensor(0.7437, device='cuda:0'),\n",
       " 'test_rec': tensor(0.7437, device='cuda:0'),\n",
       " 'test_prec': tensor(0.7437, device='cuda:0'),\n",
       " 'test_f1': tensor(0.7437, device='cuda:0')}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 ('breast_mri_3.11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cd233c12fbc226fda025f2978d6bab573f619e950f6b48dc1aaeda9d7d90bf4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
